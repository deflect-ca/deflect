
# feature parity
        * deflect-core and deflect-next stuff
          * there's probably a bit more deflect-next scripting i have to do.
          * user-uploaded https cert bundles, for one.
        * ats -> nginx porting
          * just config stuff.
        * edgemanage
          * modify it so we can ensure some number of live edges are
            deflect-next edges.
        * logging
          * make nginx output a log compatible with our current ATS format
            (deflect.log index).
          * make the auth-server output a log compatible with our current
            banjax format (banjax.log index).
        * gen_site_config() -> new sites.yml format
          * i think we should take this opportunity to clean up some sites.yml
            fields.
          * i'm imagining outputting two versions of the sites.yml.
            * the existing version goes to the existing edges. (via autodeflect)
            * a cleaned up version goes to deflect-next edges.

# nice-to-haves in various stages of completion
        * zero-downtime image upgrade with a NAT
        * self-checks during a deploy, automatic rollbacks
        * consistent versioning of configs and images
        * as many metrics as possible about what's happening at runtime.
          * IMO necessary if we're going to roll out confidently

# more detail

#### easy and done
* configurable origin port
* "purge all this site's cached content" feature
* per-site caching config:
  * some default TTL
  * list of URL regexes with overrides (like never-cache or another TTL)
  * WebsiteOptions: `cachecontrol`, `cache_time`, `cache_exceptions`
* configurable allowed http methods
        * allow/disallow HTTP DELETE, PUSH
        * actually `allowed_http_methods` seems unused (doesn't appear in deflect-web)
* `ip_allow.config`
  * allowlist some hosts that can send PURGE requests?
  * disallow purge, push for everyone else
* 50GB cache
* `proxy.config.http.negative_caching_enabled`
  * When enabled (1), Traffic Server caches negative responses (such as 404 Not
    Found) when a requested page does not exist. The next time a client
    requests the same page, Traffic Server serves the negative response directly
    from cache."
  * we have `negative_caching_lifetime` = 30 seconds
  * nginx: proxy_cache_valid 200 302 10m;
  * and: proxy_cache_valid 404      1m;
* we should get rid of the `additional_domain_prefixes`
  * we can fix this in gen_site_config() by making additional prefixes appear
    as additional sites in sites.yml.
  * or we could fix this in the database by making subsites out of these. (with
    a script, or manually if it's just a handful, i don't know)
* http(s) and subdomain prefix mapping options:
  * we should clean up how these show up in sites.yml (i think there are more
    options than we need, and some combinations are contradictory)
  * if we allow plain http, map the following:
    * http://public-name -> http://private-name
    * http://www.public-name -> http://private-name
  * optionally send redirects to https for the following:
    * http://public-name -> https://public-name
    * http://www.public-name -> https://public-name
  * if we allow https, map the following:
    * https://public-name -> https://private-name
    * https://www.public-name -> https://private-name
  * XXX i thought we offered a mode where the browser connects to our edge
    over https, but we connect to the origin over http?
* we also specify a specific TLS cipher suite
  * roles/deflect/files/build_dnet/roles/build-trafficserver/defaults/main.yml
17:server_cipher_suite: "ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-GCM-SHA256:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA"
  * any reason we hard-code this? blocking some old modes from being used?
* use hosts file only (resolv_conf is null) -- i don't see the point of this.
  we're only proxy_passing to IP addresses.
* Pin cache for edgemange object
  * `url_regex=^.*/deflectlogo_RED.png$ pin-in-cache=999d`
  * i don't know what this is for. in case our homepage happens to be offline
    when edgemanage does a health check?
* socks.config: we have some `no_socks` IPs in there -- what are they?
  * actually these just look like dummy example IPs?
* what is `bypass_remap`?
  * not in deflect-web, so can i assume it's dead code (in autodeflect?)
* `CONFIG proxy.config.ssl.server.honor_cipher_order INT 1`
  * By default (1) Traffic Server will use the server’s cipher suites preferences
    instead of the client preferences. By disabling it (0) Traffic Server will use
    client’s cipher suites preferences.

#### easy todo
* `CONFIG proxy.config.http.insert_response_via_str INT 3`
  * "add detailed transaction codes" (in Via header)
* `CONFIG proxy.config.http.cache.required_headers INT 0`
  * "No headers required to make document cacheable."
  * nginx: proxy_ignore_headers Cache-Control

#### medium - harder todo
* decrypt, verify, copy around TLS bundles (with gpg and openssl)
* logging config (this needs to play nicely with our ELK stuff...)
  * currently i have filebeat reading the stdout/stderr of every container.
  * i probably need to make it look inside the docker logging format and parse
    the nginx and auth-server formats.
  * currently we have deflect.log (ATS) and banjax.log (banjax). i'm replacing
    those two pieces of software with two other pieces of software. my gut
    feeling is that i should not introduce a schema change. it would require
    changes to our ELK stack and baskerville, and would complicate analyses of
    historical data.
  * per-site disabling of logging (really just auto-deleting)

#### things i think i can ignore but would be good to get confirmation about
* `proxy.config.http.cache.cache_responses_to_cookies`
  * "Specifies how cookies are cached:"
  * default is turned off: "Do not cache any responses to cookies."
  * only one site has it set to 1: "cache for any content-type"
  * totally ungrammatical and i have no idea what this means at all.
* `CONFIG proxy.config.cache.limits.http.max_alts INT 50`
  * Alternates arise because the HTTP 1.1 specification allows different
    documents to be sent back for the same URL (depending on the clients
    request). For example, a server might send back a GIF image to a client that
    only accepts GIF images, and might send back a JPEG image to a client that
    only accepts JPEG images.
* the following all seem to map to nginx's `proxy_cache_lock_{,age,timeout}` settings
        * `CONFIG proxy.config.cache.enable_read_while_writer INT 1`
          * Specifies when to enable the ability to read a cached object while another
            connection is completing the write to cache for that same object. The goal
            here is to avoid multiple origin connections for the same cacheable object
            upon a cache miss. The possible values of this config are:
            * 1         Always read while writing.
        * our ATS config allows unlimited doc size
        * `CONFIG proxy.config.http.cache.max_open_read_retries INT 5`
          * The number of times to attempt fetching an object from cache if there was
            an equivalent request in flight.
        * `CONFIG proxy.config.http.cache.open_read_retry_time INT 10`
          * The number of milliseconds a cacheable request will wait before requesting
            the object from cache if an equivalent request is in flight.


#### things i'm reading about in nginx that seem cool
* Delivering Cached Content When the Origin is Down
  *     proxy_cache_use_stale error timeout http_500 http_502 http_503 http_504;

* With proxy_cache_lock enabled, if multiple clients request a file that is not
  current in the cache (a MISS), only the first of those requests is allowed
  through to the origin server. The remaining requests wait for that request to
  be satisfied and then pull the file from the cache. Without proxy_cache_lock
  enabled, all requests that result in cache misses go straight to the origin
  server.
  * set this so we don't hammer auth-server when a browser loads a page?

